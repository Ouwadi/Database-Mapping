{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ad026",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031beadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "from IPython.display import display\n",
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195679bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp(\"J.J Moons\").similarity(nlp(\"J.J Moons\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca375fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the SQL Server to download Database 1 site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc754ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "conx = pyodbc.connect(\"driver={SQL SERVER}; server=failoverjoblogiclivegroup.secondary.database.windows.net; #name_of_datbase; UID= #UserID_for_database; PWD= #database_password;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd8006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write database into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b250ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Site = pd.read_sql_query('SELECT * FROM reporting.Site', conx)\n",
    "df_Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write database 2 (Excel database) into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Masterdata = pd.read_excel(r'#location of the database in your PC')\n",
    "df_Masterdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129123cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the columns to be compared and rename to match the columns in SQL server.\n",
    "df_Masterdata = df_Masterdata[[\"Outlet Id\", \"Outlet Name\",\"Outlet Street\" ,\"Outlet Postcode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f970ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick comparison to see how much site in database 2 exist in database 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16405290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Site['Site'].isin(df_Masterdata['Site']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both dataframes using unique site key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6350fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert CustomReference in Site to int32\n",
    "df_Site=df_Site.dropna(subset=['CustomReference'])\n",
    "df_Site2 = df_Site[pd.to_numeric(df_Site['CustomReference'], errors='coerce').notnull()]\n",
    "df_Site2['CustomReference'] = df_Site2['CustomReference'].astype(int)\n",
    "df_Site2.dtypes\n",
    "df_Site2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge both dataframes using CustomReference\n",
    "df_1=df_Site2.merge(df_Masterdata, on =\"CustomReference\", how='left')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename to makesure column names are clear\n",
    "df_1 = df_1.rename(columns={\"Site_x\":\"JL_Site\",\"Site_y\":\"POC_Site\",\"Address1_x\":\"JL_Address\",\"Address1_y\":\"POC_Address\",\"PostCode_x\":\"JL_PostCode\",\"PostCode_y\":\"POC_PostCode\"})\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55659a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert types for columns to string\n",
    "df_1['JL_Site'] = df_1['JL_Site'].astype(str)\n",
    "df_1['POC_Site'] = df_1['POC_Site'].astype(str)\n",
    "df_1['JL_Address'] = df_1['JL_Address'].astype(str)\n",
    "df_1['POC_Address'] = df_1['POC_Address'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e455a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make value in column lowercase\n",
    "df_1['JL_Site'] = df_1['JL_Site'].apply(lambda x:x.lower())\n",
    "df_1['POC_Site'] = df_1['POC_Site'].apply(lambda y:y.lower())\n",
    "df_1['JL_Address'] = df_1['JL_Address'].apply(lambda x:x.lower()) \n",
    "df_1['POC_Address'] = df_1['POC_Address'].apply(lambda y:y.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f45605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words from site name\n",
    "df_1['JL_Site'] = df_1['JL_Site'].astype(str).apply(lambda x: remove_stopwords(x))\n",
    "df_1['POC_Site'] = df_1['POC_Site'].astype(str).apply(lambda x: remove_stopwords(x))\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify Nouns Pronouns and Entity within site names\n",
    "df_1['JL_SiteNoun'] =df_1['JL_Site'].apply(lambda x : \" \".join([str(token) for token in nlp(x) if token.pos_ == \"NOUN\"]))\n",
    "df_1['JL_SitePronoun'] =df_1['JL_Site'].apply(lambda x : \" \".join([str(token) for token in nlp(x) if token.pos_ == \"PROPN\"]))\n",
    "df_1['JL_SiteEntity'] = df_1['JL_Site'].apply(lambda x : \" \".join([str(token) for token in nlp(x).ents]))\n",
    "df_1['JL_POCNoun'] =df_1['POC_Site'].apply(lambda x : \" \".join([str(token) for token in nlp(x) if token.pos_ == \"NOUN\"]))\n",
    "df_1['JL_POCPronoun'] =df_1['POC_Site'].apply(lambda x : \" \".join([str(token) for token in nlp(x) if token.pos_ == \"PROPN\"]))\n",
    "df_1['JL_POCEntity'] = df_1['POC_Site'].apply(lambda x : \" \".join([str(token) for token in nlp(x).ents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to make sure the noun conversation is working. \n",
    "df_1['JL_Site'].iloc[0:10].apply(lambda x : \" \".join([str(token) for token in nlp(x) if token.pos_ == \"NOUN\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to CSV so you don't have to run conversation everytime you run the code\n",
    "df_1.to_csv('SiteNLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read CSV back in\n",
    "df_1 = pd.read_csv(r'#File location for the CSV file')\n",
    "df_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78518d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert columns to string\n",
    "df_1['JL_SiteNoun']= df_1['JL_SiteNoun'].astype(str)\n",
    "df_1['JL_POCNoun']= df_1['JL_POCNoun'].astype(str)\n",
    "df_1['JL_SitePronoun']= df_1['JL_SitePronoun'].astype(str)\n",
    "df_1['JL_POCPronoun']= df_1['JL_POCPronoun'].astype(str)\n",
    "df_1['JL_SiteEntity']= df_1['JL_SiteEntity'].astype(str)\n",
    "df_1['JL_POCEntity']= df_1['JL_POCEntity'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e094a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate similarity of Nouns, Pronouns and Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun_similarity(df_1):\n",
    "  if (df_1['JL_SitePronoun'] == \"\") | (df_1['JL_POCPronoun'] == \"\") :\n",
    "    pass\n",
    "  else:\n",
    "    return nlp(df_1['JL_SitePronoun']).similarity(nlp(df_1['JL_POCPronoun']))\n",
    "\n",
    "def noun_similarity(df_1):\n",
    "    if (df_1['JL_SiteNoun'] == \"\") | (df_1['JL_POCNoun'] == \"\"):\n",
    "      pass\n",
    "    else:\n",
    "      return nlp(df_1['JL_SiteNoun']).similarity(nlp(df_1['JL_POCNoun']))\n",
    "\n",
    "def entity_similarity(df_1):\n",
    "    if (df_1['JL_SiteEntity'] == \"\") | (df_1['JL_POCEntity'] == \"\"):\n",
    "      pass\n",
    "    else:\n",
    "      return nlp(df_1['JL_SiteEntity']).similarity(nlp(df_1['JL_POCEntity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef61249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Noun_Similarity'] = df_1.apply(noun_similarity,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e011dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Pronoun_Similarity'] = df_1.apply(pronoun_similarity,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Entity_Similarity'] = df_1.apply(entity_similarity,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latitude longitude for all PostCode in the UK to enable postCode comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64770831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcode = pd.read_csv(r'#readinspreadsheet with all UK postcodes including Long and Lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87921967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcode_JLsite = df_postcode[['Postcode','uk latitude','uk longitude']]\n",
    "df_postcode_POC = df_postcode[['Postcode','uk latitude','uk longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcode_JLsite.columns = ['JL_PostCode', 'JLsite_latitude', 'JLsite_longitude']\n",
    "df_postcode_POC.columns = ['POC_PostCode', 'POC_latitude', 'POC_longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b582e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.merge(df_postcode_JLsite,how='left',on='JL_PostCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.merge(df_postcode_POC,how='left',on='POC_PostCode')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694be203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.fillna('0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b062add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "\n",
    "coords_1 = (57.097358, -2.261098)\n",
    "coords_2 = (57.097358, -3)\n",
    "\n",
    "#test to calculate the distance between two coordinates\n",
    "print(geopy.distance.geodesic(coords_1, coords_2).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(df_1):\n",
    "  if (df_1['JLsite_latitude'] != 0) | (df_1['JLsite_longitude'] != 0) | (df_1['POC_latitude'] != 0) | (df_1['POC_longitude'] != 0):\n",
    "    coords_1 = (df_1['JLsite_latitude'], df_1['JLsite_longitude'])\n",
    "    coords_2 = (df_1['POC_latitude'], df_1['POC_longitude'])\n",
    "    return geopy.distance.geodesic(coords_1, coords_2).km\n",
    "  else:\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e26432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Postcode Distance'] = df_1.apply(distance,axis=1)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_score(df_1):\n",
    "\n",
    "  if (df_1['Noun_Similarity'] != 0) & (df_1['Pronoun_Similarity'] != 0) & (df_1['Entity_Similarity'] != 0):\n",
    "    return 3\n",
    "\n",
    "  if (df_1['Noun_Similarity'] != 0) & ((df_1['Pronoun_Similarity'] != 0) | (df_1['Entity_Similarity'] != 0)):\n",
    "    return 2\n",
    "\n",
    "  if (df_1['Pronoun_Similarity'] != 0) & ((df_1['Noun_Similarity'] != 0) | (df_1['Entity_Similarity'] != 0)):\n",
    "    return 2\n",
    "\n",
    "  if (df_1['Entity_Similarity'] != 0) & ((df_1['Noun_Similarity'] != 0) | (df_1['Entity_Similarity'] != 0)):\n",
    "    return 2\n",
    "\n",
    "\n",
    "  if (df_1['Noun_Similarity'] != 0) & ((df_1['Pronoun_Similarity'] == 0) & (df_1['Entity_Similarity'] == 0)):\n",
    "    return 1\n",
    "\n",
    "  if (df_1['Pronoun_Similarity'] != 0) & ((df_1['Noun_Similarity'] == 0) & (df_1['Entity_Similarity'] == 0)):\n",
    "    return 1\n",
    "\n",
    "  if (df_1['Entity_Similarity'] != 0) & ((df_1['Noun_Similarity'] == 0) & (df_1['Entity_Similarity'] == 0)):\n",
    "    return 1\n",
    "\n",
    "  if (df_1['Entity_Similarity'] == 0) & (df_1['Noun_Similarity'] == 0) & (df_1['Entity_Similarity'] == 0):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cad194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Total Score'] = df_1.apply(total_score,axis=1)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba31c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    " def condition(df_1):\n",
    "\n",
    "   if (df_1['JL_Site'] == df_1['POC_Site']) & (df_1['JL_PostCode'] == df_1['POC_PostCode'] ) & (df_1['JL_Address'] == df_1['POC_Address'] ):\n",
    "     return \"Match\"\n",
    "\n",
    "   if (df_1['JL_Address'] != df_1['POC_Address'] ):\n",
    "     return \"Mis-match Address\"\n",
    "\n",
    "   if (df_1['Postcode Distance'] == 0) & (df_1['JL_Site'] != df_1['POC_Site']):\n",
    "     return \"Mis-match Check Name\"\n",
    "\n",
    "   if (df_1['Postcode Distance'] > 0) & (df_1['JL_Site'] == df_1['POC_Site']) :\n",
    "     return \"Mis-match Check Postcode\"    \n",
    "  \n",
    "   else:\n",
    "     return \"Mis-Match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Check'] = df_1.apply(condition,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d754b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_excel('Finaltest.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
